# -*- coding: utf-8 -*-
"""credit model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16eshRSGWnkJWrv5olVW3TMpwAbMh7VLp
"""



"""# New Section"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import StratifiedShuffleSplit, train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier

import pickle

df = pd.read_csv('/content/train_u6lujuX_CVtuZ9i.csv')
df
df.head()

pd.set_option('display.max_rows', df.shape[0]+1)

"""# New Section"""

df

pd.set_option('display.max_rows', 10)

df

#   voir les valeurs manquantes
df.info()

df.isnull().sum().sort_values(ascending=False)

df.describe()

df.describe(include='O')

# renseiner les valeurs manquantes
df

df.iloc[:]

cat_data = []
num_data = []

for i,c in enumerate(df.dtypes):
  if c == object :
    cat_data.append(df.iloc[:,i])
  else :
    num_data.append(df.iloc[:,i])

cat_data = pd.DataFrame(cat_data).transpose()
num_data = pd.DataFrame(num_data).transpose()
cat_data
num_data

cat_data.isnull().sum().any()

# type = df.dtypes

# Pour les variables catégoriques, on va remplacer les valeurs manquantes par les valeurs qui se repètent le plus
cat_data = cat_data.apply(lambda x:x.fillna(x.value_counts().index[0]))
cat_data.isnull().sum().any()

# Pour les variables numériques, on va remplacer les valeurs manquantes par la valeur précédente de la meme colonnes
num_data.fillna(method='bfill', inplace=True)
num_data.isnull().sum().any()

# Transformer la colonne Target
target_value = {'Y':1, 'N':0}
target = cat_data['Loan_Status']
cat_data.drop('Loan_Status', axis=1, inplace=True)
target = target.map(target_value)
target

# Remplacer les valeurs catégoriques par des valeurs numériques 0,1,2,...
le = LabelEncoder()
for i in cat_data:
  cat_data[i] = le.fit_transform(cat_data[i])
cat_data

# Supprimer Loan_id
cat_data.drop('Loan_ID', axis=1, inplace=True)

# Concatener num_data et cat_data et spécifier la colonne target
X = pd.concat([cat_data, num_data], axis=1)
y = target

X

y



# On va commencer par la variable target
target.value_counts()

# la base de données utilisée pour EDA
df=pd.concat([cat_data,num_data,target],axis=1)

plt.figure(figsize=(8,6))
# sns.countplot(target[0])
sns.countplot(target)

# Calculer les pourcentages

yes = target.value_counts()[1]/len(target)
no = target.value_counts()[0]/len(target)
# Afficher les pourcentages
print(f'Le pourcentage des crédits accordés est : {yes * 100:.2f}%')
print(f'Le pourcentage des crédits non accordés est : {no * 100:.2f}%')

# Afficher le diagramme
plt.show()



# Credit history
grid = sns.FacetGrid(df, col='Loan_Status',  aspect=1.6)
grid.map(sns.countplot, 'Credit_History')

# Sexe
grid = sns.FacetGrid(df, col='Loan_Status', aspect=1.6)
grid.map(sns.countplot, 'Gender')

# Sexe
grid = sns.FacetGrid(df, col='Loan_Status', aspect=1.6)
grid.map(sns.countplot, 'Married')

# Education
grid = sns.FacetGrid(df, col='Loan_Status', aspect=1.6)
grid.map(sns.countplot, 'Education')

# Revenu du demandeur
plt.scatter(df['ApplicantIncome'], df['Loan_Status'])

# Revenu du demandeur
plt.scatter(df['CoapplicantIncome'], df['Loan_Status'])

df.groupby('Loan_Status').median()



# Diviser la base de donnée en une base de donnée de test et d'entrainement
sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
for train, test in sss.split(X,y):
  X_train, X_test = X.iloc[train], X.iloc[test]
  y_train, y_test = y.iloc[train], y.iloc[test]

print('X_train taille : ', X_train.shape)
print('X_test taille : ', X_test.shape)
print('y_train taille : ', y_train.shape)
print('y_test taille : ', y_test.shape)

# On va appliquer trois algorithmes Logisitic Regression, KNN, DecisionTree
models={
'LogisticRegression' : LogisticRegression(random_state=42),
'KNeighborsClassifier' : KNeighborsClassifier(),
'DecisionTreeClassifier' : DecisionTreeClassifier(max_depth=1, random_state=42)
}

# La fonction de précision
def accu(y_true, y_pred, retu=False):
  accu = accuracy_score(y_true, y_pred)
  if retu:
    return accu
  else :
    print(f'La précision du modèle est : {accu}')

# C'est la fonction d'application des modèles
def train_test_eval(models, X_train, y_train, X_test, y_test):
  for name, model in models.items():
    print(name, ' : ')
    model.fit(X_train, y_train)
    accu(y_test, model.predict(X_test))
    print('_'*30)
train_test_eval(models, X_train, y_train, X_test, y_test)

X_2 = X[['Credit_History','Married', 'CoapplicantIncome']]

# Diviser la base de donnée en une base de donnée de test et d'entrainement
sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
for train, test in sss.split(X_2,y):
  X_train, X_test = X_2.iloc[train], X_2.iloc[test]
  y_train, y_test = y.iloc[train], y.iloc[test]

print('X_train taille : ', X_train.shape)
print('X_test taille : ', X_test.shape)
print('y_train taille : ', y_train.shape)
print('y_test taille : ', y_test.shape)

train_test_eval(models, X_train, y_train, X_test, y_test)

# Appliquer la regression logistique sur notre base de donnée
Classifier = LogisticRegression()
Classifier.fit(X_2, y)

# Enregistrer le modèle
pickle.dump(Classifier, open('model.pkl', 'wb'))

